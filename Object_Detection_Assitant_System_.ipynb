{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS playsound\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5AOgxv03541",
        "outputId": "de624c23-7d41-4843-8237-d1178b4ae4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: playsound in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.1.31)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.17.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.1->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "5yYSG7oTDsH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import io\n",
        "import uuid\n",
        "import requests\n",
        "import numpy as np\n",
        "import cv2\n",
        "import inflect\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "from gtts import gTTS\n"
      ],
      "metadata": {
        "id": "GbFsyspCDmeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Helper Function: Load Image from URL\n",
        "\n"
      ],
      "metadata": {
        "id": "rtMh_yEoDuTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_from_url(url: str) -> Image.Image | None:\n",
        "    \"\"\"\n",
        "    Load an image from a URL.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the image.\n",
        "\n",
        "    Returns:\n",
        "        PIL.Image.Image or None: The loaded image, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        return Image.open(io.BytesIO(response.content))\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "FgmRvPBJDmVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper Function: Render Detection Results\n"
      ],
      "metadata": {
        "id": "OhrYHVkDD4wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def render_results_in_image(in_pil_img: Image.Image, in_results: list) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Draw bounding boxes and labels on an image based on detection results.\n",
        "\n",
        "    Args:\n",
        "        in_pil_img (PIL.Image.Image): The original image.\n",
        "        in_results (list): List of detection dictionaries with keys 'box', 'label', and 'score'.\n",
        "\n",
        "    Returns:\n",
        "        PIL.Image.Image: The annotated image.\n",
        "    \"\"\"\n",
        "    # Convert the PIL image (RGB) to an OpenCV image (BGR)\n",
        "    img = cv2.cvtColor(np.array(in_pil_img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Loop through each prediction and draw bounding boxes and labels\n",
        "    for prediction in in_results:\n",
        "        x = prediction['box']['xmin']\n",
        "        y = prediction['box']['ymin']\n",
        "        w = prediction['box']['xmax'] - x\n",
        "        h = prediction['box']['ymax'] - y\n",
        "        label_text = f\"{prediction['label']}: {round(prediction['score'] * 100, 1)}%\"\n",
        "\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(img, label_text, (x, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "    # Convert back to a PIL image (RGB)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(img_rgb)\n"
      ],
      "metadata": {
        "id": "7aVIFsAuDmJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper Function: Summarize Predictions\n"
      ],
      "metadata": {
        "id": "IQL_6o5tD891"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_predictions_natural_language(predictions: list) -> str:\n",
        "    \"\"\"\n",
        "    Create a natural language summary from detection results.\n",
        "\n",
        "    Args:\n",
        "        predictions (list): List of detection dictionaries.\n",
        "\n",
        "    Returns:\n",
        "        str: A summary of the detected objects.\n",
        "    \"\"\"\n",
        "    if not predictions:\n",
        "        return \"No objects were detected in the image.\"\n",
        "\n",
        "    counts = {}\n",
        "    p = inflect.engine()\n",
        "\n",
        "    # Count each detected object type\n",
        "    for prediction in predictions:\n",
        "        label = prediction['label']\n",
        "        counts[label] = counts.get(label, 0) + 1\n",
        "\n",
        "    # Create a descriptive sentence for the summary\n",
        "    descriptions = [\n",
        "        f\"{p.number_to_words(count)} {label}{'s' if count > 1 else ''}\"\n",
        "        for label, count in counts.items()\n",
        "    ]\n",
        "    if len(descriptions) == 1:\n",
        "        description_text = descriptions[0]\n",
        "    else:\n",
        "        description_text = \", \".join(descriptions[:-1]) + f\", and {descriptions[-1]}\"\n",
        "\n",
        "    return f\"In this image, there are {description_text}.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "nQujmNvHDmGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialize the Object Detection Pipeline\n"
      ],
      "metadata": {
        "id": "7VtUjmc1EL94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "od_pipe = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD4SjekIDmE7",
        "outputId": "8cbf80d9-f33e-41c7-a7fe-2802ca92ef67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper Function: Generate Audio Description using gTTS\n"
      ],
      "metadata": {
        "id": "gBeGeZWvEPox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_audio_description(predictions: list) -> str:\n",
        "    \"\"\"\n",
        "    Generate an audio narration from detection results.\n",
        "\n",
        "    Args:\n",
        "        predictions (list): List of detection dictionaries.\n",
        "\n",
        "    Returns:\n",
        "        str: The file path of the generated audio.\n",
        "    \"\"\"\n",
        "    description = summarize_predictions_natural_language(predictions)\n",
        "    tts = gTTS(text=description, lang='en')\n",
        "    # Create a unique filename for each audio output to avoid overwrites\n",
        "    audio_path = f\"output_{uuid.uuid4().hex}.mp3\"\n",
        "    tts.save(audio_path)\n",
        "    return audio_path\n",
        "\n"
      ],
      "metadata": {
        "id": "cRw7MQVtDmBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function: Process Image and Generate Outputs\n"
      ],
      "metadata": {
        "id": "N0dsor6mEbPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pipeline_prediction_with_audio(pil_image: Image.Image) -> tuple:\n",
        "    \"\"\"\n",
        "    Process an input image to detect objects, annotate the image, and generate an audio summary.\n",
        "\n",
        "    Args:\n",
        "        pil_image (PIL.Image.Image): The input image.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (Annotated image, Audio file path)\n",
        "    \"\"\"\n",
        "    # Run object detection\n",
        "    pipeline_output = od_pipe(pil_image)\n",
        "    # Render the detections on the image\n",
        "    processed_image = render_results_in_image(pil_image, pipeline_output)\n",
        "    # Generate audio description\n",
        "    audio_file = generate_audio_description(pipeline_output)\n",
        "    return processed_image, audio_file\n"
      ],
      "metadata": {
        "id": "X997tymYDl-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Gradio Interface\n"
      ],
      "metadata": {
        "id": "Xk88Q2rdEiwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=get_pipeline_prediction_with_audio,\n",
        "    inputs=gr.Image(label=\"Input Image\", type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Annotated Image\", type=\"pil\"),\n",
        "        gr.Audio(label=\"Audio Description\")\n",
        "    ],\n",
        "    title=\"Object Detection Assistant\",\n",
        "    description=\"Upload an image to see detected objects and hear an audio description.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "s7eaM5IGEhIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch the Gradio App\n"
      ],
      "metadata": {
        "id": "FR_gA6xFEpQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n",
        "    except OSError:\n",
        "        print(\"Port 7860 is busy, launching on a different port.\")\n",
        "        demo.launch(server_name=\"0.0.0.0\", share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "s775q7KmDlPN",
        "outputId": "6f9f3c39-7ac5-4ebc-dd68-2c71287c2964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Port 7860 is busy, launching on a different port.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b607ef49e57724a68.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b607ef49e57724a68.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}